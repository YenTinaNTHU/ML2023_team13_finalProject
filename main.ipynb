{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b959842e-0154-42f1-b2c1-c24905221572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from torch.utils import data\n",
    "from dataset import*\n",
    "from config import settings\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import*\n",
    "from train_test import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be7740-64f5-44b8-803e-6112b5be8816",
   "metadata": {},
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e230a955-19d1-419e-a8c2-d5072eafd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv file shape: (1000, 8)\n",
      "setting time info...\n",
      "setting geo info...\n",
      "counting net fare...\n"
     ]
    }
   ],
   "source": [
    "transformers = {\n",
    "        'year': MinMaxScaler(), # Normalize\n",
    "        'weekday': None,\n",
    "        'time': StandardScaler(), # Standardlize\n",
    "        'weather': None\n",
    "    }\n",
    "df, transformers = load_data('train', total_sample=1000, random_sample=settings.totalN, scaling_transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9417a69d-d9eb-43b2-8730-f7ab13731234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature</th>\n",
       "      <th>weathercode</th>\n",
       "      <th>distance</th>\n",
       "      <th>total_fixed_fees</th>\n",
       "      <th>net_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.00000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.593365</td>\n",
       "      <td>1.597046</td>\n",
       "      <td>0.466245</td>\n",
       "      <td>0.131857</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.140295</td>\n",
       "      <td>0.158228</td>\n",
       "      <td>0.14557</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>0.138186</td>\n",
       "      <td>0.019515</td>\n",
       "      <td>0.293249</td>\n",
       "      <td>11.698418</td>\n",
       "      <td>7.614979</td>\n",
       "      <td>2.106930</td>\n",
       "      <td>3.349684</td>\n",
       "      <td>8.243681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.397605</td>\n",
       "      <td>1.218509</td>\n",
       "      <td>0.305274</td>\n",
       "      <td>0.338513</td>\n",
       "      <td>0.362156</td>\n",
       "      <td>0.347477</td>\n",
       "      <td>0.365147</td>\n",
       "      <td>0.35286</td>\n",
       "      <td>0.337361</td>\n",
       "      <td>0.345277</td>\n",
       "      <td>0.980635</td>\n",
       "      <td>0.455492</td>\n",
       "      <td>10.456101</td>\n",
       "      <td>17.771293</td>\n",
       "      <td>2.310894</td>\n",
       "      <td>0.411464</td>\n",
       "      <td>9.420634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.096872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.691985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805291</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.359922</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.538643</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>9.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.493395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>24.529855</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>63.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount  passenger_count        year      Sunday      Monday  \\\n",
       "count   948.000000       948.000000  948.000000  948.000000  948.000000   \n",
       "mean     11.593365         1.597046    0.466245    0.131857    0.155063   \n",
       "std       9.397605         1.218509    0.305274    0.338513    0.362156   \n",
       "min       3.300000         1.000000    0.000000    0.000000    0.000000   \n",
       "25%       6.000000         1.000000    0.166667    0.000000    0.000000   \n",
       "50%       8.500000         1.000000    0.500000    0.000000    0.000000   \n",
       "75%      13.300000         2.000000    0.666667    0.000000    0.000000   \n",
       "max      66.300000         6.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          Tuesday   Wednesday   Thursday      Friday    Saturday        hour  \\\n",
       "count  948.000000  948.000000  948.00000  948.000000  948.000000  948.000000   \n",
       "mean     0.140295    0.158228    0.14557    0.130802    0.138186    0.019515   \n",
       "std      0.347477    0.365147    0.35286    0.337361    0.345277    0.980635   \n",
       "min      0.000000    0.000000    0.00000    0.000000    0.000000   -2.096872   \n",
       "25%      0.000000    0.000000    0.00000    0.000000    0.000000   -0.691985   \n",
       "50%      0.000000    0.000000    0.00000    0.000000    0.000000    0.088508   \n",
       "75%      0.000000    0.000000    0.00000    0.000000    0.000000    0.869001   \n",
       "max      1.000000    1.000000    1.00000    1.000000    1.000000    1.493395   \n",
       "\n",
       "       is_holiday  temperature  weathercode    distance  total_fixed_fees  \\\n",
       "count  948.000000   948.000000   948.000000  948.000000        948.000000   \n",
       "mean     0.293249    11.698418     7.614979    2.106930          3.349684   \n",
       "std      0.455492    10.456101    17.771293    2.310894          0.411464   \n",
       "min      0.000000   -17.700000     0.000000    0.000166          2.500000   \n",
       "25%      0.000000     3.700000     0.000000    0.805291          3.000000   \n",
       "50%      0.000000    12.150000     1.000000    1.359922          3.300000   \n",
       "75%      1.000000    20.400000     3.000000    2.538643          3.500000   \n",
       "max      1.000000    37.900000    75.000000   24.529855          4.300000   \n",
       "\n",
       "         net_fare  \n",
       "count  948.000000  \n",
       "mean     8.243681  \n",
       "std      9.420634  \n",
       "min      0.100000  \n",
       "25%      2.600000  \n",
       "50%      5.300000  \n",
       "75%      9.900000  \n",
       "max     63.800000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b5297d-32e0-4151-9ed6-0eab877df922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9265b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fare_amount', 'passenger_count', 'year', 'Sunday', 'Monday', 'Tuesday',\n",
       "       'Wednesday', 'Thursday', 'Friday', 'Saturday', 'hour', 'is_holiday',\n",
       "       'temperature', 'weathercode', 'distance', 'from_JKF', 'to_JKF',\n",
       "       'from_LGA', 'to_LGA', 'to_EWR', 'from_Manhattan', 'to_Manhattan',\n",
       "       'total_fixed_fees', 'net_fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11225e-f077-42dd-ba2c-8ca6d5b0c60f",
   "metadata": {},
   "source": [
    "## Training and validation data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14f0570-b57e-4f96-afd1-f6e79799f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = DataFolder(split='train', df=df, transformers=transformers)\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489332c-e038-4b95-aa84-58db890306df",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = DataFolder(split='valid', df=df, transformers=transformers)\n",
    "valid_dataloader = data.DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329a2f6-3ec9-45b6-b307-d1920e974b19",
   "metadata": {},
   "source": [
    "## Mode select val or train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5f5a7-14d6-4cce-ac73-d531930391bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mode_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d117a-c237-48d2-af36-cff527401e88",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb2f29-0313-4830-b8e3-f95526efef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef73f3-f2ed-4912-b593-4a2bfaec23a6",
   "metadata": {},
   "source": [
    "## Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea6b68-2343-49fb-9036-7e67133b8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FCNN32 with BN'\n",
    "save_model_name = './model/'+ model_name +'.pth'\n",
    "loss_filename = './loss curve/' + model_name + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2015, 0, ..., True, 4.3, 6.7],\n",
       "       [6, 2014, 0, ..., True, 3.0, 2.0],\n",
       "       [1, 2012, 0, ..., True, 4.0, 5.699999999999999],\n",
       "       ...,\n",
       "       [1, 2014, 0, ..., False, 3.5, 12.0],\n",
       "       [2, 2010, 0, ..., True, 3.5, 2.2],\n",
       "       [2, 2014, 0, ..., True, 4.0, 6.0]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c8612-5548-4da5-a766-85c635e3e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension = 23\n",
      "FCNN(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = np.size(train_dataset.features, 1)\n",
    "print(f'feature dimension = {input_dim}')\n",
    "if Mode_train:\n",
    "    model = FCNN(input_dim=input_dim).to(device) \n",
    "else:\n",
    "    model = FCNN(input_dim=input_dim)\n",
    "    model.load_state_dict(torch.load(save_model_name))\n",
    "    model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c1135-7f74-418e-ad3f-af81c7ac7872",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31d0d3-411e-44ed-846c-14186396683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# optimizer2 = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=0, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d9841-bc82-4c00-b262-00e0be61f62d",
   "metadata": {},
   "source": [
    "## Training epoch and stop condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2332d6f-746f-4c30-a634-1101bb62b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9809ec9-0bf5-4f6c-8bf1-79cd9ce53137",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./logs/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d737e30-b70e-4fe8-9bcf-e01d397e0627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:23<00:00,  1.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     loss_record \u001b[39m=\u001b[39m [\u001b[39m1e6\u001b[39m, \u001b[39m1e6\u001b[39m, \u001b[39m1e6\u001b[39m, \u001b[39m1e6\u001b[39m, \u001b[39m1e6\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[39m=\u001b[39m train(train_dataloader, model, loss_fn, optimizer, writer\u001b[39m=\u001b[39;49mwriter, record_batches\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m     val_loss \u001b[39m=\u001b[39m val(valid_dataloader, model, loss_fn)\n\u001b[1;32m      8\u001b[0m     writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mloss/training\u001b[39m\u001b[39m\"\u001b[39m, train_loss, epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ML/ML_final_project/NewYorkCityTaxiFarePrediction/train_test.py:23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, writer, record_batches)\u001b[0m\n\u001b[1;32m     19\u001b[0m batch_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     21\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     24\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1444\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if Mode_train:\n",
    "    epochs = 50\n",
    "    if not trained:\n",
    "        loss_record = [1e6, 1e6, 1e6, 1e6, 1e6]\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer, writer=writer, record_batches=200)\n",
    "        val_loss = val(valid_dataloader, model, loss_fn)\n",
    "        writer.add_scalar(\"loss/training\", train_loss, epoch+1)\n",
    "        writer.add_scalar(\"loss/validation\", val_loss, epoch+1)\n",
    "        print(f\"Epoch {epoch + 1:2d}: Loss = {train_loss:.4f}\") \n",
    "        print(f'valid loss = {val_loss:.4f}')\n",
    "        loss_record.append(train_loss)\n",
    "        # if train_loss > sum(loss_record[-5:])/5*1.05 or train_loss < 0.1:\n",
    "        #     print('Early stop!')\n",
    "        #     break\n",
    "\n",
    "    if not trained:        \n",
    "        del loss_record[0:5]\n",
    "    trained = True    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeccd69-c913-47c4-bc99-e940d2b51691",
   "metadata": {},
   "source": [
    "## Plot training loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be937485-68fa-4dc4-af1a-172937f9ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curve(loss_list):\n",
    "    plt.plot(loss_list)\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921241a4-84fb-40bf-ac81-a5f5581a6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mode_train:\n",
    "    plot_loss_curve(loss_record)\n",
    "else:\n",
    "    print('Auto load loss curve')\n",
    "    with open(loss_filename) as fh:\n",
    "        s = fh.readline()\n",
    "        L = s[1:-1].split(', ')\n",
    "        loss_record = [float(x) for x in L]        \n",
    "    plot_loss_curve(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc168e95-d799-48f2-9096-a5eb429cd162",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41223d-4c78-4904-a0d5-e38d3c7420d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 584.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final valid loss = 1.2435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#final_train_loss = val(train_dataloader, model, loss_fn)\n",
    "final_val_loss = val(valid_dataloader, model, loss_fn)\n",
    "print(f'final valid loss = {final_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdad2f-6c4e-4451-9f5a-e3966809aac9",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76e36c-6773-4a9b-95a2-730be3af8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mode_train:\n",
    "    torch.save(model.state_dict(), save_model_name)\n",
    "    with open(loss_filename, 'w') as fh:\n",
    "        fh.writelines(str(loss_record))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b583fe-1fe0-44a7-99f7-777355e9da95",
   "metadata": {},
   "source": [
    "## Output test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9c3efe-d359-46d1-b3f2-f58c39d9f346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded test csv file shape: (9914, 7)\n",
      "setting time info...\n",
      "setting geo info...\n",
      "counting fixed fee...\n"
     ]
    }
   ],
   "source": [
    "test_dataset = DataFolder(split='test', transformers=transformers)\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd00804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_dataset.key_list, columns=[\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d8b167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                key\n",
       "count                          9914\n",
       "unique                         9914\n",
       "top     2015-01-27 13:08:24.0000002\n",
       "freq                              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb398d-c907-4050-9b97-b008f18ddbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/155 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x22 and 23x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(test_dataset\u001b[39m.\u001b[39mkey_list, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[39m=\u001b[39m test(test_dataloader, model)\n\u001b[1;32m      5\u001b[0m df_test[\u001b[39m\"\u001b[39m\u001b[39mfare_amount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m predictions\u001b[39m+\u001b[39mdf_test[\u001b[39m\"\u001b[39m\u001b[39mtotal_fixed_fees\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[39m# 將dataframe保存為CSV文件\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML/ML_final_project/NewYorkCityTaxiFarePrediction/train_test.py:78\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     76\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 78\u001b[0m         pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     79\u001b[0m         predictions\u001b[39m.\u001b[39mappend(pred\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     81\u001b[0m predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(predictions, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ML/ML_final_project/NewYorkCityTaxiFarePrediction/model.py:23\u001b[0m, in \u001b[0;36mFCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_relu_stack(x)\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_2023/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x22 and 23x32)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = test(test_dataloader, model)\n",
    "\n",
    "df_test[\"fare_amount\"] = predictions+df_test[\"total_fixed_fees\"]\n",
    "df_\n",
    "# 將dataframe保存為CSV文件\n",
    "df_test.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a0e18-b48a-4984-bea6-62da849fb7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
