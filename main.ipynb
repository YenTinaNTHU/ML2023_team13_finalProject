{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b959842e-0154-42f1-b2c1-c24905221572",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m settings\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m\u001b[39m*\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_test\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/ML/ML_final_project/NewYorkCityTaxiFarePrediction/train_test.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from torch.utils import data\n",
    "from dataset import*\n",
    "from config import settings\n",
    "from model import*\n",
    "from train_test import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be7740-64f5-44b8-803e-6112b5be8816",
   "metadata": {},
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e230a955-19d1-419e-a8c2-d5072eafd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv file shape: (55423856, 8)\n"
     ]
    }
   ],
   "source": [
    "df = load_data('train', random_sample=settings.totalN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9417a69d-d9eb-43b2-8730-f7ab13731234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fare_amount  passenger_count      year  Sunday  Monday  Tuesday  Wednesday   \n",
      "0          4.5                1  0.000000   False   False    False      False  \\\n",
      "1         16.9                1  0.166667    True   False    False      False   \n",
      "2          5.7                2  0.333333   False   False     True      False   \n",
      "3          7.7                1  0.500000   False   False    False      False   \n",
      "4          5.3                1  0.166667    True   False    False      False   \n",
      "\n",
      "   Thursday  Friday  Saturday      hour  is_holiday  distance  from_JKF   \n",
      "0     False   False      True  0.739130           0  0.640487     False  \\\n",
      "1     False   False     False  0.695652           0  5.250670     False   \n",
      "2     False   False     False  0.000000           0  0.863411     False   \n",
      "3      True   False     False  0.173913           1  1.739386     False   \n",
      "4     False   False     False  0.304348           0  1.242218     False   \n",
      "\n",
      "   to_JKF  from_LGA  to_LGA  to_EWR  from_Manhattan  to_Manhattan  \n",
      "0   False     False   False   False           False         False  \n",
      "1   False     False   False   False           False          True  \n",
      "2   False     False   False   False            True          True  \n",
      "3   False     False   False   False            True          True  \n",
      "4   False     False   False   False            True          True  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b5297d-32e0-4151-9ed6-0eab877df922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53838850, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11225e-f077-42dd-ba2c-8ca6d5b0c60f",
   "metadata": {},
   "source": [
    "## Training and validation data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14f0570-b57e-4f96-afd1-f6e79799f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dataset = DataFolder(split='train', df=df)\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f489332c-e038-4b95-aa84-58db890306df",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = DataFolder(split='valid', df=df)\n",
    "valid_dataloader = data.DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329a2f6-3ec9-45b6-b307-d1920e974b19",
   "metadata": {},
   "source": [
    "## Mode select val or train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a5f5a7-14d6-4cce-ac73-d531930391bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mode_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d117a-c237-48d2-af36-cff527401e88",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2cb2f29-0313-4830-b8e3-f95526efef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:4 device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef73f3-f2ed-4912-b593-4a2bfaec23a6",
   "metadata": {},
   "source": [
    "## Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce5d1c2-cfd6-4a4c-bb82-89f01813f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),   \n",
    "            nn.ReLU(),             \n",
    "            nn.Linear(512, 1),   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cea6b68-2343-49fb-9036-7e67133b8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_name = './model/FCNN512t512t512.pth'\n",
    "loss_filename = './loss curve/FCNN512t512t512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c66c8612-5548-4da5-a766-85c635e3e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension = 19\n"
     ]
    }
   ],
   "source": [
    "input_dim = np.size(train_dataset.features, 1)\n",
    "print(f'feature dimension = {input_dim}')\n",
    "if Mode_train:\n",
    "    model = FCNN(input_dim=input_dim).to(device) \n",
    "else:\n",
    "    model = FCNN(input_dim=input_dim)\n",
    "    model.load_state_dict(torch.load(save_model_name))\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c1135-7f74-418e-ad3f-af81c7ac7872",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba31d0d3-411e-44ed-846c-14186396683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d9841-bc82-4c00-b262-00e0be61f62d",
   "metadata": {},
   "source": [
    "## Training epoch and stop condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2332d6f-746f-4c30-a634-1101bb62b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d737e30-b70e-4fe8-9bcf-e01d397e0627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▍                                                                                                                                                               | 7215/336493 [01:19<55:55, 98.13it/s]"
     ]
    }
   ],
   "source": [
    "if Mode_train:\n",
    "    epochs = 1\n",
    "    if not trained:\n",
    "        loss_record = [1e6, 1e6, 1e6, 1e6, 1e6]\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        val_loss = val(valid_dataloader, model, loss_fn)\n",
    "        print(f\"Epoch {epoch + 1:2d}: Loss = {train_loss:.4f}\") \n",
    "        print(f'valid loss = {val_loss:.4f}')\n",
    "        loss_record.append(train_loss)\n",
    "        # if train_loss > sum(loss_record[-5:])/5*1.05 or train_loss < 0.1:\n",
    "        #     print('Early stop!')\n",
    "        #     break\n",
    "\n",
    "    if not trained:        \n",
    "        del loss_record[0:5]\n",
    "    trained = True    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeccd69-c913-47c4-bc99-e940d2b51691",
   "metadata": {},
   "source": [
    "## Plot training loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be937485-68fa-4dc4-af1a-172937f9ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curve(loss_list):\n",
    "    plt.plot(loss_list)\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921241a4-84fb-40bf-ac81-a5f5581a6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mode_train:\n",
    "    plot_loss_curve(loss_record)\n",
    "else:\n",
    "    print('Auto load loss curve')\n",
    "    with open(loss_filename) as fh:\n",
    "        s = fh.readline()\n",
    "        L = s[1:-1].split(', ')\n",
    "        loss_record = [float(x) for x in L]        \n",
    "    plot_loss_curve(loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc168e95-d799-48f2-9096-a5eb429cd162",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e41223d-4c78-4904-a0d5-e38d3c7420d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84124/84124 [05:10<00:00, 271.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final valid loss = 3.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#final_train_loss = val(train_dataloader, model, loss_fn)\n",
    "final_val_loss = val(valid_dataloader, model, loss_fn)\n",
    "print(f'final valid loss = {final_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdad2f-6c4e-4451-9f5a-e3966809aac9",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76e36c-6773-4a9b-95a2-730be3af8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mode_train:\n",
    "    torch.save(model.state_dict(), save_model_name)\n",
    "    with open(loss_filename, 'w') as fh:\n",
    "        fh.writelines(str(loss_record))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b583fe-1fe0-44a7-99f7-777355e9da95",
   "metadata": {},
   "source": [
    "## Output test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c3efe-d359-46d1-b3f2-f58c39d9f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DataFolder(split='test')\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb398d-c907-4050-9b97-b008f18ddbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_dataset.key_list, columns=[\"key\"])\n",
    "\n",
    "predictions = test(test_dataloader, model)\n",
    "\n",
    "df_test[\"fare_amount\"] = predictions\n",
    "\n",
    "# 將dataframe保存為CSV文件\n",
    "df_test.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a0e18-b48a-4984-bea6-62da849fb7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
